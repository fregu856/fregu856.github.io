<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Fredrik K. Gustafsson | PhD Student in Probabilistic Deep Learning on Fredrik K. Gustafsson | PhD Student in Probabilistic Deep Learning</title>
    <link>/</link>
    <description>Recent content in Fredrik K. Gustafsson | PhD Student in Probabilistic Deep Learning on Fredrik K. Gustafsson | PhD Student in Probabilistic Deep Learning</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; Fredrik K. Gustafsson 2023</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The How and Why of Reading 300 Papers in 5 Years</title>
      <link>/post/phd_of_reading/</link>
      <pubDate>Thu, 22 Jun 2023 00:00:00 +0200</pubDate>
      
      <guid>/post/phd_of_reading/</guid>
      <description>

&lt;p&gt;&lt;em&gt;The header image above was generated using the text-to-image tool at &lt;a href=&#34;https://www.imagine.art/dashboard/tool/from-text&#34; target=&#34;_blank&#34;&gt;imagine.art&lt;/a&gt;, from the input &amp;ldquo;teddy bear scientists having an intense discussion in a reading group about machine learning&amp;rdquo;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Since I started my PhD almost five years ago (in September 2018), I have categorized, annotated and written short comments for all research papers I read in detail. I share this publicly in a &lt;a href=&#34;https://github.com/fregu856/papers&#34; target=&#34;_blank&#34;&gt;GitHub repository&lt;/a&gt;, and recently reached 300 read papers. To mark this milestone, I decided to share some thoughts on why I think it&amp;rsquo;s important to read a lot of papers, and how I organize my reading. I also compiled some paper statistics, along with a list of 30 papers that I found particularly interesting and/or well-written.&lt;/p&gt;

&lt;h4 id=&#34;why-i-read-a-lot-of-papers&#34;&gt;Why I read a lot of papers&lt;/h4&gt;

&lt;p&gt;The simple reason as to why I try to read a lot of papers, is that I find it very enjoyable and interesting. Among all the different everyday activities of a typical PhD student, reading papers is one of my clear favorites. However, I also think it&amp;rsquo;s key for becoming a good researcher. In fact, I consider reading papers to be a fundamental part of what it even means to be a researcher.&lt;/p&gt;

&lt;p&gt;First of all, I have found it to be a very powerful tool for learning new things. It&amp;rsquo;s actually quite remarkable how much you can learn about a certain machine learning problem or method simply by reading e.g. 5 papers about it in detail.&lt;/p&gt;

&lt;p&gt;Secondly, I think it&amp;rsquo;s a great way to generate new research ideas. When reading an interesting paper, I virtually always get at least one idea about how the proposed approach potentially could be extended in some way, or how it could be combined with some of my previous work.&lt;/p&gt;

&lt;h4 id=&#34;how-i-m-able-to-read-a-lot-of-papers&#34;&gt;How I&amp;rsquo;m able to read a lot of papers&lt;/h4&gt;

&lt;p&gt;As a PhD student, I&amp;rsquo;m always quite busy with research, teaching duties, coursework and other meetings. In my experience, the single most important thing one can do in order to read a lot of papers is therefore to &lt;em&gt;actively prioritize reading&lt;/em&gt;. This means setting aside some time in your schedule each week, specifically for reading. Aiming to read at least one paper a week has generally worked well for me, and I thus make sure to schedule at least one 1-2 hour time slot each week. By treating reading just like any other weekly meeting, I have (almost) always been able to find time for it.&lt;/p&gt;

&lt;p&gt;The second most important thing one can do is probably to join (or start) a reading group. I&amp;rsquo;ve been organizing a weekly &lt;a href=&#34;https://www.it.uu.se/about_us/divisions/systems_and_control/activities/mlreadinggroup&#34; target=&#34;_blank&#34;&gt;machine learning reading group&lt;/a&gt; at our division since I started as a PhD student. Being a member of a reading group makes it much easier to actually set aside time to read e.g. one paper a week.&lt;/p&gt;

&lt;p&gt;Joining a reading group also comes with many other benefits. First of all, it&amp;rsquo;s a good way to &amp;ldquo;force&amp;rdquo; yourself to read papers you wouldn&amp;rsquo;t necessarily have selected yourself (such papers can be surprisingly interesting). I think this is important, to not just read the very latest state-of-the-art papers within your specific area of interest. Instead, I think one should actively try to branch out a little and also read some older papers, and papers from other areas.&lt;/p&gt;

&lt;p&gt;Moreover, discussing a paper you&amp;rsquo;ve read in a reading group almost always significantly improves your understanding of the paper. Joining a reading group is also a great way to learn more about your colleagues’ research and interests, and of course, discussing papers with other people is a generally fun and enjoyable activity in itself.&lt;/p&gt;

&lt;h4 id=&#34;how-i-organize-my-paper-reading&#34;&gt;How I organize my paper reading&lt;/h4&gt;

&lt;p&gt;For each paper I read in detail, I create a note somewhere where I can easily find it later. In this note, I write down any questions, thoughts or ideas which arise during reading. Reading papers can generate a lot of research ideas, and they all seem obvious right there and then, but if you don’t write them down they will be very difficult to remember in the future. A PhD is long, you might want to go back to a certain read paper years later, and then such notes (even if they are very brief) can be incredibly useful.&lt;/p&gt;

&lt;p&gt;Afterwards, I also write a very short summary of the paper, quickly answering questions such as &amp;ldquo;Was the paper interesting overall?&amp;rdquo;, &amp;ldquo;Was it easy to understand?&amp;rdquo; or &amp;ldquo;Could it be relevant for my research now or in the future?&amp;rdquo;. Having short answers to simple questions like these can also turn out to be surprisingly helpful.&lt;/p&gt;

&lt;p&gt;For each paper, I also annotate the pdf and upload it to my &lt;a href=&#34;https://github.com/fregu856/papers/tree/master/commented_pdfs&#34; target=&#34;_blank&#34;&gt;GitHub repository&lt;/a&gt; (i.e., somewhere where I can easily find it later). I strongly recommend getting a tablet for reading and annotating papers, it really does make a big difference.&lt;/p&gt;

&lt;p&gt;The main reason for why I annotate each paper is that this makes it easier to stay focused while reading. I find that actively annotating a paper &amp;ldquo;forces&amp;rdquo; you to actually try to understand what you&amp;rsquo;re reading. Moreover, it enables you to go back to a paper years later and quickly find the most interesting and important information.&lt;/p&gt;

&lt;h4 id=&#34;why-i-share-my-reading-publicly&#34;&gt;Why I share my reading publicly&lt;/h4&gt;

&lt;p&gt;The reason why I share a list of all my read papers publicly on &lt;a href=&#34;https://github.com/fregu856/papers&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; is somewhat of a coincidence, it&amp;rsquo;s mostly just an idea I happened to have one day when I started my PhD. Now almost five years later, it is however something that I definitely can recommend.&lt;/p&gt;

&lt;p&gt;There are of course much more advanced tools such as &lt;a href=&#34;https://www.zotero.org/&#34; target=&#34;_blank&#34;&gt;Zotero&lt;/a&gt; (which I&amp;rsquo;m sure can be super useful and convenient), but I really enjoy the simplicity of my &amp;ldquo;GitHub repository&amp;rdquo; system, and it seems to provide all the features I need. For example, it enables me to go back and very quickly find particular papers that I&amp;rsquo;ve read before.&lt;/p&gt;

&lt;p&gt;Moreover, I strongly believe in the general principles of open science. Open exchange and publication of information are defining features of the scientific community, and publicly sharing all of my reading in this way is, at least to me, a natural next step towards truly transparent and accessible research.&lt;/p&gt;

&lt;p&gt;Last but not least, publicly sharing my reading definitely motivates me to read more papers. It adds a bit of external pressure and encouragement to stay consistent with my reading, to actually set aside some time (almost) every week. Without it, I&amp;rsquo;m quite confident that I wouldn&amp;rsquo;t have been able to reach 300 read papers already.&lt;/p&gt;

&lt;h4 id=&#34;how-i-find-interesting-papers-to-read&#34;&gt;How I find interesting papers to read&lt;/h4&gt;

&lt;p&gt;To read a lot of papers, one also has to find a lot of interesting papers. I regularly look for interesting new and old papers, for example by checking:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;arXiv.&lt;/li&gt;
&lt;li&gt;Twitter.&lt;/li&gt;
&lt;li&gt;Accepted papers lists for upcoming and previous conferences.&lt;/li&gt;
&lt;li&gt;The references in interesting papers.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;Cited by&amp;rdquo; list on Google Scholar for interesting papers.&lt;/li&gt;
&lt;li&gt;A list of people whose research I find particularly interesting, occasionally checking arXiv/scholar for their new papers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I have a (nearly) daily habit of quickly going through all new &lt;a href=&#34;https://arxiv.org/list/cs.LG/recent&#34; target=&#34;_blank&#34;&gt;cs.LG&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/list/cs.CV/recent&#34; target=&#34;_blank&#34;&gt;cs.CV&lt;/a&gt; papers on arXiv, and spending 5 minutes scrolling through twitter. The number of papers on arXiv keeps increasing every year, but I still find it manageable and worthwhile to go through them daily (typically, this takes at most 20-30 min). There are many aspects of twitter that I really don&amp;rsquo;t like (thus I limit myself to 5 min per day), but I must admit that it&amp;rsquo;s a good tool for finding interesting papers, researchers, workshops, seminars etc.&lt;/p&gt;

&lt;p&gt;Whenever I find a seemingly interesting paper, I go through it very quickly (check the abstract, scroll through the method and/or experiments) and decide whether or not it still seems interesting. If so, I then save it somewhere where I easily can go back and find it later. Specifically, I put the paper titles in Google Keep lists, and if a paper seems especially interesting I also make a short note about that. Once I have time to read a paper in detail, I then go through my lists of interesting papers and pick one.&lt;/p&gt;

&lt;h3 id=&#34;30-particularly-interesting-and-or-well-written-papers&#34;&gt;30 Particularly Interesting and/or Well-Written Papers&lt;/h3&gt;

&lt;p&gt;I went through my comments for all 300 read papers, and selected a list of 30 papers that I found particularly interesting and/or well-written:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Uncertainty Estimation:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1505.05424&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Weight Uncertainty in Neural Networks&lt;/em&gt;&lt;/a&gt; (ICML 2015)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1902.03932&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning&lt;/em&gt;&lt;/a&gt; (ICLR 2020)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.14806&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Laplace Redux &amp;ndash; Effortless Bayesian Deep Learning&lt;/em&gt;&lt;/a&gt; (NeurIPS 2021)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1802.07095&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Uncertainty Estimates and Multi-Hypotheses Networks for Optical Flow&lt;/em&gt;&lt;/a&gt; (ECCV 2018)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1805.12114&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models&lt;/em&gt;&lt;/a&gt; (NeurIPS 2018)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.5555/3295222.3295241&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Selective Classification for Deep Neural Networks&lt;/em&gt;&lt;/a&gt; (NeurIPS 2017)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://proceedings.neurips.cc/paper/2019/file/5103c3584b063c431bd1268e9b5e76fb-Paper.pdf&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Conformalized Quantile Regression&lt;/em&gt;&lt;/a&gt; (NeurIPS 2019)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2107.00649&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;On the Practicality of Deterministic Epistemic Uncertainty&lt;/em&gt;&lt;/a&gt; (ICML 2022)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Out-of-Distribution Detection:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2102.08248&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Hierarchical VAEs Know What They Don&amp;rsquo;t Know&lt;/em&gt;&lt;/a&gt; (ICML 2021)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1807.03888&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks&lt;/em&gt;&lt;/a&gt; (NeurIPS 2018)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.12051&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;SSD: A Unified Framework for Self-Supervised Outlier Detection&lt;/em&gt;&lt;/a&gt; (ICLR 2021)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.06507&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Out-of-Distribution Detection with Deep Nearest Neighbors&lt;/em&gt;&lt;/a&gt; (ICML 2022)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.10065&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Being a Bit Frequentist Improves Bayesian Neural Networks&lt;/em&gt;&lt;/a&gt; (AISTATS 2022)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2110.14019&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Reliable and Trustworthy Machine Learning for Health Using Dataset Shift Detection&lt;/em&gt;&lt;/a&gt; (NeurIPS 2021)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S1361841521003194?via%3Dihub&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Does Your Dermatology Classifier Know What It Doesn&amp;rsquo;t Know? Detecting the Long-Tail of Unseen Conditions&lt;/em&gt;&lt;/a&gt; (Medical Image Analysis, 2022)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Energy-Based Models:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.jmlr.org/papers/v6/hyvarinen05a.html&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Estimation of Non-Normalized Statistical Models by Score Matching&lt;/em&gt;&lt;/a&gt; (JMLR, 2005)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Noise-Contrastive Estimation: A New Estimation Principle for Unnormalized Statistical Models&lt;/em&gt;&lt;/a&gt; (AISTATS 2010)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1903.12370&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;On the Anatomy of MCMC-Based Maximum Likelihood Learning of Energy-Based Models&lt;/em&gt;&lt;/a&gt; (AAAI 2020)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1912.03263&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One&lt;/em&gt;&lt;/a&gt; (ICLR 2020)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1912.00589&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Flow Contrastive Estimation of Energy-Based Models&lt;/em&gt;&lt;/a&gt; (CVPR 2020)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.06059&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Joint Training of Variational Auto-Encoder and Latent Energy-Based Model&lt;/em&gt;&lt;/a&gt; (CVPR 2020)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Other:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.08934&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis&lt;/em&gt;&lt;/a&gt; (ECCV 2020)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.13938&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Neural Unsigned Distance Fields for Implicit Function Learning&lt;/em&gt;&lt;/a&gt; (NeurIPS 2020)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1904.05866&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Expressive Body Capture: 3D Hands, Face, and Body from a Single Image&lt;/em&gt;&lt;/a&gt; (CVPR 2019)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1907.03961&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;A Baseline for 3D Multi-Object Tracking&lt;/em&gt;&lt;/a&gt; (IROS 2020)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.04551&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Learning Latent Dynamics for Planning from Pixels&lt;/em&gt;&lt;/a&gt; (ICML 2019)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://link.springer.com/article/10.1007/s43681-021-00122-8&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Blind Spots in AI Ethics&lt;/em&gt;&lt;/a&gt; (AI and Ethics, 2022)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://link.springer.com/article/10.1007/s43681-022-00209-w&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;The Uselessness of AI Ethics&lt;/em&gt;&lt;/a&gt; (AI and Ethics, 2022)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.12871&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Why AI is Harder Than We Think&lt;/em&gt;&lt;/a&gt; (GECCO 2021)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.03551&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Talking About Large Language Models&lt;/em&gt;&lt;/a&gt; (arXiv, 2022)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;paper-statistics&#34;&gt;Paper Statistics&lt;/h3&gt;

&lt;p&gt;I compiled some more detailed statistics of my read papers (number of papers read each year, papers by publication year, papers by venue, papers by category):&lt;/p&gt;

&lt;p&gt;303 read papers.&lt;/p&gt;

&lt;p&gt;1.84 GB of annotated pdfs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/phd_of_reading/papers_read_each_year.svg&#34; alt=&#34;Papers read each year&#34; /&gt;
&lt;img src=&#34;/img/phd_of_reading/papers_by_publication_year.svg&#34; alt=&#34;Papers by publication year&#34; /&gt;
&lt;img src=&#34;/img/phd_of_reading/papers_by_venue.svg&#34; alt=&#34;Papers by venue&#34; /&gt;
&lt;img src=&#34;/img/phd_of_reading/papers_by_category.svg&#34; alt=&#34;Papers by category&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Refusion: Enabling Large-Size Realistic Image Restoration with Latent-Space Diffusion Models</title>
      <link>/publication/refusion/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/publication/refusion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How Reliable is Your Regression Model&#39;s Uncertainty Under Real-World Distribution Shifts?</title>
      <link>/publication/regression_uncertainty/</link>
      <pubDate>Tue, 07 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/publication/regression_uncertainty/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image Restoration with Mean-Reverting Stochastic Differential Equations</title>
      <link>/publication/ir_sde/</link>
      <pubDate>Fri, 27 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/publication/ir_sde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ECG-Based Electrolyte Prediction: Evaluating Regression and Probabilistic Methods</title>
      <link>/publication/regressionecg/</link>
      <pubDate>Wed, 21 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/publication/regressionecg/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explaining Machine Learning and How It Can Be Used to Help Doctors</title>
      <link>/post/explaining_ml/</link>
      <pubDate>Mon, 07 Feb 2022 00:00:00 +0100</pubDate>
      
      <guid>/post/explaining_ml/</guid>
      <description>&lt;p&gt;For a project in the doctoral course &lt;em&gt;Using Maths and CS to do Social Good&lt;/em&gt; at Uppsala University, our goal was to make grade 7-9 students more interested in mathematics. To that end, we have created a &lt;a href=&#34;https://youtu.be/5G4cmSh4s-4&#34; target=&#34;_blank&#34;&gt;video&lt;/a&gt; with an accompanying &lt;a href=&#34;https://educaora.com/@MachineLearningDoc&#34; target=&#34;_blank&#34;&gt;interactive blog post&lt;/a&gt;. In the video, we explain the essence of how machine learning works and how it can be used to help doctors discover heart attacks from patient ECGs. &lt;em&gt;There is also a &lt;a href=&#34;https://youtu.be/5ehdIBaElYA&#34; target=&#34;_blank&#34;&gt;Swedish version&lt;/a&gt; of the video.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We tailor our explanation of machine learning to grade 7-9 students by basing it on the concept of straight lines (linear functions). We start by showing how a straight line can be fitted to some collected data and then used to make predictions, for example to predict ice cream sales from the outside temperature.
&lt;img src=&#34;/img/explaining_ml/img2.png&#34; alt=&#34;Illustrative ice cream example&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We then explain what ECGs are and how they are used by doctors when a patient comes to a hospital and complains about chest pain, trying to determine if the patient has a heart attack or not.
&lt;img src=&#34;/img/explaining_ml/img4.png&#34; alt=&#34;Chest pain, ECG, heart attack?&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, we generalize our initial ice cream sales vs. outside temperature example to explain how machine learning can be used also to predict heart attack risk from a patient ECG, and how this can be used to help doctors discover patients who have heart attacks.
&lt;img src=&#34;/img/explaining_ml/img5.png&#34; alt=&#34;Prediction of heart attack risk&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Project group:&lt;/br&gt;
&lt;a href=&#34;https://dgedon.github.io/&#34; target=&#34;_blank&#34;&gt;Daniel Gedon&lt;/a&gt;, &lt;a href=&#34;https://katalog.uu.se/profile/?id=N20-1420&#34; target=&#34;_blank&#34;&gt;Erik Hallström&lt;/a&gt; &amp;amp; Fredrik K. Gustafsson&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Proposals for Practical Energy-Based Regression</title>
      <link>/publication/ebms_proposals/</link>
      <pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/publication/ebms_proposals/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Uncertainty-Aware Body Composition Analysis with Deep Regression Ensembles on UK Biobank MRI</title>
      <link>/publication/mri_regression/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/publication/mri_regression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Energy-Based NARX Models</title>
      <link>/publication/ebms_narx/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/publication/ebms_narx/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Accurate 3D Object Detection using Energy-Based Models</title>
      <link>/publication/ebms_3dod/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/publication/ebms_3dod/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to Train Your Energy-Based Model for Regression</title>
      <link>/publication/ebms_regression/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/publication/ebms_regression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Energy-Based Models for Deep Probabilistic Regression</title>
      <link>/publication/dctd/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/dctd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer Vision</title>
      <link>/publication/evaluating_bdl/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/evaluating_bdl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Getting Started with PyTorch:&lt;br&gt; 1 - Linear Regression</title>
      <link>/post/19apr/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0200</pubDate>
      
      <guid>/post/19apr/</guid>
      <description>

&lt;p&gt;&lt;em&gt;All code found in this blog post is also available on &lt;a href=&#34;https://colab.research.google.com/drive/1UfqfzEvaq18a2b8Y7kHTU8iAfOVzbF6t&#34; target=&#34;_blank&#34;&gt;Google Colab&lt;/a&gt; where it can be executed directly in the browser.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When I first got interested in deep learning a couple of years ago, I started out using &lt;a href=&#34;https://www.tensorflow.org/&#34; target=&#34;_blank&#34;&gt;TensorFlow&lt;/a&gt;. In early 2018 I then decided to switch to &lt;a href=&#34;https://pytorch.org/&#34; target=&#34;_blank&#34;&gt;PyTorch&lt;/a&gt;, a decision that I&amp;rsquo;ve been very happy with ever since. Today, the difference between the two frameworks is probably quite small in practice (and both are extensively used by researchers in the field), but I &lt;em&gt;personally&lt;/em&gt; still find PyTorch more convenient to use.&lt;/p&gt;

&lt;p&gt;In a short series of blog posts I thus intend to try and help anyone interested in the field to get started with PyTorch and deep learning, by providing (hopefully) clearly written code examples.&lt;/p&gt;

&lt;p&gt;In this first post, we&amp;rsquo;ll start with perhaps the most simple example problem there is and try to fit a straight line to some noisy data points. We will however do so using &lt;a href=&#34;http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentvariants&#34; target=&#34;_blank&#34;&gt;mini-batch Stochastic Gradient Descent (SGD)&lt;/a&gt; and use the same basic code structure that can be used also for significantly more interesting problems, such as &lt;a href=&#34;https://github.com/fregu856/deeplabv3&#34; target=&#34;_blank&#34;&gt;street-scene semantic segmentation&lt;/a&gt; or &lt;a href=&#34;https://github.com/fregu856/3DOD_thesis&#34; target=&#34;_blank&#34;&gt;automotive 3D object detection&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Essentially, we need to specify just three things: a dataset class, a model class and a training loop.&lt;/p&gt;

&lt;h3 id=&#34;dataset&#34;&gt;Dataset&lt;/h3&gt;

&lt;p&gt;For our dataset class, we need to specify a constructor and two member functions.&lt;/p&gt;

&lt;p&gt;In the constructor &lt;code&gt;__init__&lt;/code&gt;, we create a synthetic dataset $D = \{(x_1, y_1), \dots, (x_N, y_N)\}$ by drawing $x_i$ uniformly from an interval and adding Gaussian noise to a given straight line:
\[
x_i \sim U[-3, 3], \quad i = 1, \dots, N,
\]
\[
y_i = \bar{k}x_i + \bar{m} + \epsilon_i, \quad \epsilon_i \sim \mathcal{N}(0, 0.5), \quad i = 1, \dots, N.
\]&lt;/p&gt;

&lt;p&gt;We also assign the number of examples, $N$, to a member variable so that it can be returned by &lt;code&gt;__len__&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Finally, in &lt;code&gt;__getitem__&lt;/code&gt; we return the corresponding example $(x_i, y_i)$ given an index $i \in \{1, \dots, N\}$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import torch
import torch.utils.data

import numpy as np

import matplotlib.pyplot as plt

class LinearRegressionDataset(torch.utils.data.Dataset):
    def __init__(self, k, m, N):
        self.X = np.random.uniform(low=-3.0, high=3.0, size=(N, )) # (shape: (N, ))

        epsilon = np.random.normal(loc=0.0, scale=0.5, size=(N, )) # (shape: (N, ))

        self.Y = k*self.X + m + epsilon # (shape: (N, ))

        plt.figure(figsize=(8, 6))
        plt.plot(self.X, self.Y, &amp;quot;^k&amp;quot;, label=&amp;quot;Training data examples&amp;quot;)
        plt.plot([-3, 3], [k*(-3)+m, k*3+m], &amp;quot;r&amp;quot;, label=&amp;quot;True straight line&amp;quot;)
        plt.legend()
        plt.ylabel(&amp;quot;y&amp;quot;)
        plt.xlabel(&amp;quot;x&amp;quot;)
        plt.show()

        self.num_examples = N

        self.X = self.X.astype(np.float32)
        self.Y = self.Y.astype(np.float32)

    def __getitem__(self, index):
        x = self.X[index]

        y = self.Y[index]

        return (x, y)

    def __len__(self):
        return self.num_examples

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In &lt;code&gt;__init__&lt;/code&gt;, we also plot our created dataset $D = \{(x_1, y_1), \dots, (x_N, y_N)\}$ together with the true straight line $y = \bar{k}x + \bar{m}$. For $\bar{k} = 3$, $\bar{m}= 5$, $N= 50$, we get the following plot:
&lt;img src=&#34;/img/19apr/1.png&#34; alt=&#34;Plot of our training dataset&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;

&lt;p&gt;For our model class, we need to specify a constructor and one member function.&lt;/p&gt;

&lt;p&gt;In the constructor &lt;code&gt;__init__&lt;/code&gt;, we create our two model parameters $k, m$ and assign them to member variables. These are then used in &lt;code&gt;forward&lt;/code&gt; to output a prediction $\hat{y} = kx + m$ for a given input $x$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import torch.nn as nn

class LinearRegressionModel(nn.Module):
    def __init__(self):
        super(LinearRegressionModel, self).__init__()

        self.k = nn.Parameter(torch.zeros(1)) # (shape: (1))
        self.m = nn.Parameter(torch.zeros(1)) # (shape: (1))

    def forward(self, x):
        # (x has shape: (batch_size))

        y_hat = self.k*x + self.m # (shape: (batch_size))

        return y_hat

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;training-loop&#34;&gt;Training loop&lt;/h3&gt;

&lt;p&gt;To train our model on the dataset using SGD, we create instances of &lt;code&gt;LinearRegressionDataset&lt;/code&gt; and &lt;code&gt;LinearRegressionModel&lt;/code&gt;, we create the data loader &lt;code&gt;train_loader&lt;/code&gt; (which will repeatedly call &lt;code&gt;LinearRegressionDataset.__getitem__&lt;/code&gt; to create mini-batches), and create the SGD optimizer object &lt;code&gt;optimizer&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We then iterate through the entire dataset with mini-batches of size &lt;code&gt;batch_size&lt;/code&gt;, and for each mini-batch we compute the L2 loss $L(k, m) = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2,$ we compute the gradients of this mini-batch loss with respect to our model parameters, and finally use these gradients in the SGD step to update the parameters.&lt;/p&gt;

&lt;p&gt;One such iteration through the dataset is called an epoch, and we repeat this process &lt;code&gt;num_epochs&lt;/code&gt; times.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
from torch.autograd import Variable

num_epochs = 25
learning_rate = 0.01
batch_size = 8

k = 3
m = 5
N = 50

train_dataset = LinearRegressionDataset(k=k, m=m, N=N)

num_train_batches = int(len(train_dataset)/batch_size)
print (&amp;quot;num train batches per epoch: %d&amp;quot; % num_train_batches)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size, shuffle=True,
                                           num_workers=1)

model = LinearRegressionModel()
model = model.cuda()
model.train() # (set in training mode, this affects BatchNorm and dropout)

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

epoch_losses_train = []
for epoch in range(num_epochs):
    print (&amp;quot;###########################&amp;quot;)
    print (&amp;quot;epoch: %d/%d&amp;quot; % (epoch+1, num_epochs))

    batch_losses = []
    for step, (x, y) in enumerate(train_loader):
        x = Variable(x).cuda() # (shape: (batch_size))
        y = Variable(y).cuda() # (shape: (batch_size))

        y_hat = model(x) # (shape: (batch_size))

        loss = torch.mean(torch.pow(y - y_hat, 2))

        # optimization step:
        optimizer.zero_grad() # (reset gradients)
        loss.backward() # (compute gradients)
        optimizer.step() # (perform the SGD update of the model parameters)

        # store the loss value:
        loss_value = loss.data.cpu().numpy()
        batch_losses.append(loss_value)

    epoch_loss = np.mean(batch_losses)
    epoch_losses_train.append(epoch_loss)
    print (&amp;quot;train loss: %g&amp;quot; % epoch_loss)

plt.figure(figsize=(8, 6))
plt.plot(epoch_losses_train, &amp;quot;^k&amp;quot;)
plt.plot(epoch_losses_train, &amp;quot;k&amp;quot;)
plt.ylabel(&amp;quot;Loss&amp;quot;)
plt.xlabel(&amp;quot;Epoch&amp;quot;)
plt.title(&amp;quot;Loss per epoch&amp;quot;)
plt.show()

print (&amp;quot;k, true value: %g, estimated value: %g&amp;quot; % (k, model.k))
print (&amp;quot;m, true value: %g, estimated value: %g&amp;quot; % (m, model.m))

plt.figure(figsize=(8, 6))
plt.plot(train_dataset.X, train_dataset.Y, &amp;quot;^k&amp;quot;, label=&amp;quot;Training data examples&amp;quot;)
plt.plot([-3, 3], [k*(-3)+m, k*3+m], &amp;quot;r&amp;quot;, label=&amp;quot;True straight line&amp;quot;)
plt.plot([-3, 3], [model.k*(-3)+model.m, model.k*3+model.m], &amp;quot;b&amp;quot;,
         label=&amp;quot;Estimated straight line&amp;quot;)
plt.legend()
plt.ylabel(&amp;quot;y&amp;quot;)
plt.xlabel(&amp;quot;x&amp;quot;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In each epoch, we also store all mini-batch losses and then average them to get a loss value for the entire dataset. Once training is completed, we plot these epoch losses:
&lt;img src=&#34;/img/19apr/2.png&#34; alt=&#34;Plot of the training loss per epoch&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As we can see, the loss quickly decreases in the beginning and then starts to level out as our model parameters $k, m$ get close to the true values $\bar{k} = 3$, $\bar{m}= 5$. We also plot our estimated straight line $\hat{y} = kx + m$ and compare it to the true one:
&lt;img src=&#34;/img/19apr/3.png&#34; alt=&#34;Plot of our training dataset, the true straight line and our estimated straight line&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;additional-visualizations&#34;&gt;Additional visualizations&lt;/h3&gt;

&lt;p&gt;Since we in this simple example problem have just two model parameters, we can gain additional insight by computing our loss function $L(k, m) = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2$ (over the entire dataset) for different values of $k, m$ and plot the loss surface:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
num_values=100
k_plot_values = np.linspace(start=(k-7.0), stop=(k+7.0), num=num_values)
m_plot_values = np.linspace(start=(m-7.0), stop=(m+7.0), num=num_values)
# (k_plot_values and m_plot_values both have shape: (num_values, ))
loss_values = np.zeros((num_values, num_values))
for k_i in range(num_values):
    for m_i in range(num_values):
        Y_hat = k_plot_values[k_i]*train_dataset.X + m_plot_values[m_i]
        # (Y_hat has shape: (N, ))

        loss = np.mean((train_dataset.Y - Y_hat)**2)
        loss_values[m_i, k_i] = loss

plt.figure(figsize=(8, 6))
K, M = np.meshgrid(k_plot_values, m_plot_values)
plt.contour(K, M, loss_values, levels=20)
plt.plot(k, m, &amp;quot;r*&amp;quot;, label=&amp;quot;True parameters&amp;quot;)
plt.legend()
plt.ylabel(&amp;quot;m&amp;quot;)
plt.xlabel(&amp;quot;k&amp;quot;)
plt.title(&amp;quot;Loss surface&amp;quot;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/img/19apr/4.png&#34; alt=&#34;Plot of the loss surface&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, we can also store the current values of $k, m$ at different points during training and plot the parameter trajectory, starting at the initial point $(k_0 = 0, m_0 = 0)$ and ending at our final estimate $(k = 3.03, m = 4.86)$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
model = LinearRegressionModel()
model = model.cuda()
model.train() # (set in training mode, this affects BatchNorm and dropout)

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

epoch_losses_train = []
k_values = []
m_values = []
k_values.append(model.k.data.cpu().numpy())
m_values.append(model.m.data.cpu().numpy())
for epoch in range(num_epochs):
    print (&amp;quot;###########################&amp;quot;)
    print (&amp;quot;epoch: %d/%d&amp;quot; % (epoch+1, num_epochs))

    batch_losses = []
    for step, (x, y) in enumerate(train_loader):
        x = Variable(x).cuda() # (shape: (batch_size))
        y = Variable(y).cuda() # (shape: (batch_size))

        y_hat = model(x) # (shape: (batch_size))

        loss = torch.mean(torch.pow(y - y_hat, 2))

        # optimization step:
        optimizer.zero_grad() # (reset gradients)
        loss.backward() # (compute gradients)
        optimizer.step() # (perform the SGD update of the model parameters)

        # store the loss value:
        loss_value = loss.data.cpu().numpy()
        batch_losses.append(loss_value)

    epoch_loss = np.mean(batch_losses)
    epoch_losses_train.append(epoch_loss)
    print (&amp;quot;train loss: %g&amp;quot; % epoch_loss)

    k_values.append(model.k.data.cpu().numpy())
    m_values.append(model.m.data.cpu().numpy())

plt.figure(figsize=(8, 6))
plt.plot(epoch_losses_train, &amp;quot;^k&amp;quot;)
plt.plot(epoch_losses_train, &amp;quot;k&amp;quot;)
plt.ylabel(&amp;quot;Loss&amp;quot;)
plt.xlabel(&amp;quot;Epoch&amp;quot;)
plt.title(&amp;quot;Loss per epoch&amp;quot;)
plt.show()

print (&amp;quot;k, true value: %g, estimated value: %g&amp;quot; % (k, model.k))
print (&amp;quot;m, true value: %g, estimated value: %g&amp;quot; % (m, model.m))

plt.figure(figsize=(8, 6))
plt.plot(train_dataset.X, train_dataset.Y, &amp;quot;^k&amp;quot;, label=&amp;quot;Training data examples&amp;quot;)
plt.plot([-3, 3], [k*(-3)+m, k*3+m], &amp;quot;r&amp;quot;, label=&amp;quot;True straight line&amp;quot;)
plt.plot([-3, 3], [model.k*(-3)+model.m, model.k*3+model.m], &amp;quot;b&amp;quot;,
         label=&amp;quot;Estimated straight line&amp;quot;)
plt.legend()
plt.ylabel(&amp;quot;y&amp;quot;)
plt.xlabel(&amp;quot;x&amp;quot;)
plt.show()

num_values=100
k_plot_values = np.linspace(start=(k-7.0), stop=(k+7.0), num=num_values)
m_plot_values = np.linspace(start=(m-7.0), stop=(m+7.0), num=num_values)
# (k_plot_values and m_plot_values both have shape: (num_values, ))
loss_values = np.zeros((num_values, num_values))
for k_i in range(num_values):
    for m_i in range(num_values):
        Y_hat = k_plot_values[k_i]*train_dataset.X + m_plot_values[m_i]
        # (Y_hat has shape: (N, ))

        loss = np.mean((train_dataset.Y - Y_hat)**2)
        loss_values[m_i, k_i] = loss

plt.figure(figsize=(8, 6))
K, M = np.meshgrid(k_plot_values, m_plot_values)
plt.contour(K, M, loss_values, levels=20)
plt.plot(k, m, &amp;quot;r*&amp;quot;, label=&amp;quot;True parameters&amp;quot;)
plt.plot(k_values, m_values, &amp;quot;xb&amp;quot;, label=&amp;quot;Estimated parameters&amp;quot;)
plt.plot(k_values, m_values, &amp;quot;b&amp;quot;)
plt.legend()
plt.ylabel(&amp;quot;m&amp;quot;)
plt.xlabel(&amp;quot;k&amp;quot;)
plt.title(&amp;quot;Parameter trajectory&amp;quot;)
plt.show()

plt.figure(figsize=(8, 6))
K, M = np.meshgrid(k_plot_values, m_plot_values)
plt.contour(K, M, loss_values, levels=20)
plt.plot(k, m, &amp;quot;r*&amp;quot;, label=&amp;quot;True parameters&amp;quot;)
plt.plot(k_values, m_values, &amp;quot;xb&amp;quot;, label=&amp;quot;Estimated parameters&amp;quot;)
plt.plot(k_values, m_values, &amp;quot;b&amp;quot;)
plt.legend()
plt.ylabel(&amp;quot;m&amp;quot;)
plt.xlabel(&amp;quot;k&amp;quot;)
plt.xlim([k-3.0, k+3.0])
plt.ylim([m-3.0, m+3.0])
plt.title(&amp;quot;Parameter trajectory - Zoomed&amp;quot;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/img/19apr/7.png&#34; alt=&#34;Plot of the trajectory of the model parameters during training&#34; /&gt;
&lt;img src=&#34;/img/19apr/8.png&#34; alt=&#34;Zoomed plot of the trajectory of the model parameters during training&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Feel free to &lt;a href=&#34;/#contact&#34;&gt;contact&lt;/a&gt; me or post a comment below if you have any questions or comments. In the next blog post, we&amp;rsquo;ll do nonlinear curve-fitting using feed-forward neural networks.&lt;/em&gt;&lt;/p&gt;

&lt;!-- ```console
num train batches per epoch: 6
###########################
epoch: 1/25
train loss: 50.0857
###########################
epoch: 2/25
train loss: 25.0836
``` --&gt;
</description>
    </item>
    
    <item>
      <title>PyTorch Implementation of DeepLabV3</title>
      <link>/project/deeplabv3/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/deeplabv3/</guid>
      <description>&lt;p&gt;PyTorch implementation of &lt;a href=&#34;https://arxiv.org/abs/1706.05587&#34; target=&#34;_blank&#34;&gt;DeepLabV3&lt;/a&gt;, trained on the Cityscapes dataset. Please see the GitHub repository linked below for code and further details.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Fredrik K. Gustafsson | PhD Student in Probabilistic Deep Learning</title>
    <link>/project/</link>
    <description>Recent content in Projects on Fredrik K. Gustafsson | PhD Student in Probabilistic Deep Learning</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; Fredrik K. Gustafsson 2020</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PyTorch Implementation of DeepLabV3</title>
      <link>/project/deeplabv3/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/deeplabv3/</guid>
      <description>PyTorch implementation of DeepLabV3, trained on the Cityscapes dataset. Please see the GitHub repository linked below for code and further details.</description>
    </item>
    
    <item>
      <title>Stinspira</title>
      <link>/project/stinspira/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/stinspira/</guid>
      <description>Website (in Swedish) aiming to increase interest in higher education among youths. Web design, logo design and content creation. stinspira.se.</description>
    </item>
    
    <item>
      <title>Skalman</title>
      <link>/project/skalman/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/skalman/</guid>
      <description>Ongoing project.</description>
    </item>
    
    <item>
      <title>SMAUGS</title>
      <link>/project/smaugs/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/smaugs/</guid>
      <description>By Fredrik K. Gustafsson, Andreas Hägglund, Andreas Lundgren, Elin Näsholm, Fredrik Tormod, Hampus Andersson, Jonathan Jerner and Mattias Andreasson.
My main responsibilities: SLAM and ROS.</description>
    </item>
    
    <item>
      <title>2D Object Detection for Autonomous Driving</title>
      <link>/project/2dod/</link>
      <pubDate>Sat, 02 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/2dod/</guid>
      <description>TensorFlow implementation of SqueezeDet, trained on the KITTI dataset. The results in the video above can obviously be improved, but because of limited computing resources (personally funded Azure VM) I did not perform any further hyperparameter tuning. Please see the GitHub repository linked below for code and further details.</description>
    </item>
    
    <item>
      <title>Semantic Segmentation for Autonomous Driving</title>
      <link>/project/segmentation/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/segmentation/</guid>
      <description>TensorFlow implementation of ENet, trained on the Cityscapes dataset. The results in the video above can obviously be improved, but because of limited computing resources (personally funded Azure VM) I did not perform any further hyperparameter tuning. Please see the GitHub repository linked below for code and further details.</description>
    </item>
    
    <item>
      <title>ROSperino</title>
      <link>/project/rosperino/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/rosperino/</guid>
      <description>Features include video streaming, a web interface for manual control and SLAM using both the camera and the LiDAR separately.</description>
    </item>
    
    <item>
      <title>Summer Internship Project</title>
      <link>/project/zenuity/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/zenuity/</guid>
      <description>Deep learning demo/test platform based on a standard 1&amp;frasl;10 scale RC car. Using a web interface, one can manually control the car and run a variety of deep learning algorithms on streaming video, including the end-to-end trained system for obstacle avoidance shown in the video above.</description>
    </item>
    
    <item>
      <title>AA 273 Final Project</title>
      <link>/project/aa273/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/aa273/</guid>
      <description>We study the SE-Sync algorithm and how it can be utilized for pose-graph SLAM. We begin by presenting a historical review of the general SLAM problem and the optimization based paradigm of pose-graph SLAM. We then proceed to carefully define the pose-graph SLAM problem and present an intuitive but still sufficiently complete treatment of the SE-Sync algorithm and how it is applied to solve the corresponding optimization problem.
Our main contribution is an implementation of SE-Sync in a ROS compatible SLAM system obtained by replacing the back-end optimizer of an existing open source implementation.</description>
    </item>
    
    <item>
      <title>CS 224N Final Project</title>
      <link>/project/cs224n/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/cs224n/</guid>
      <description>Motivated by the future need of intelligent systems for vehicle-to-passenger communication in autonomous vehicles, we implement two models for automatic image caption generation based on the neural encoder-decoder framework.
Following an extensive hyperparameter search, our non-attention based model achieves performance on the MSCOCO dataset highly comparable to that of its reference model. Our attention based model does however fail to exceed this performance, despite the attention mechanism appearing to function as intended.</description>
    </item>
    
    <item>
      <title>CS 229 Final Project</title>
      <link>/project/cs229/</link>
      <pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/cs229/</guid>
      <description>In this project, we apply reinforcement learning techniques to control an inverted double pendulum on a cart. We successfully learn a controller for balancing in a simulation environment using Q-learning with a linear function approximator, without any prior knowledge of the system at hand. We do however fail to learn a controller for the swing-up maneuver, which leads to a discussion on what might be needed to solve more complex control problems using reinforcement learning.</description>
    </item>
    
    <item>
      <title>Summer Internship Project</title>
      <link>/project/t/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/t/</guid>
      <description>Web tool for analysis and visualization of car engine sensor data for a fleet of test vehicles, developed using Python (Flask), MySQL and Bootstrap.</description>
    </item>
    
    <item>
      <title>Rasperino</title>
      <link>/project/rasperino/</link>
      <pubDate>Fri, 01 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/rasperino/</guid>
      <description>Main hardware:
- 1x Arduino Uno.
- 1x Raspberry Pi 3 Model B.
- 1x Raspberry Pi Camera Module v2.
- 1x DFRobot 4WD Arduino Mobile Platform.
- 2x L298 Dual H-Bridge DC Motor Controller.
- 5x Sharp GP2Y0A21YK0F IR Range Sensor - 10 cm to 80 cm.
- 1x Power bank.
Features:
- Autonomous navigation of simple mazes.
- Basic computer vision for detection of &#34;color signs&#34;.
- Video streaming.</description>
    </item>
    
    <item>
      <title>Spider Pig</title>
      <link>/project/spiderpig/</link>
      <pubDate>Wed, 01 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/spiderpig/</guid>
      <description>Main hardware:
- 1x PhantomX AX Metal Hexapod Mark II Kit (including 18x Dynamixel AX-12 servos, excluding the ArbotiX Robocontroller).
- 3x ATmega1284p microcontrollers.
- 7x IR distance sensors.
- 1x ultrasonic distance sensor.
- 1x MPU-6050 IMU.
- 1x LCD display.
- 1x FireFly Bluetooth modem.
- 1x Raspberry Pi 3 Model B.
- 1x Raspberry Pi Camera Board 5 MP.
Functionality:
- The robot can navigate a simple maze (containing both low and high obstacles) autonomously and be controlled manually with an Xbox controller connected to a PC.</description>
    </item>
    
    <item>
      <title>BlueWind</title>
      <link>/project/bluewind/</link>
      <pubDate>Tue, 01 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/project/bluewind/</guid>
      <description>By Fredrik K. Gustafsson, Olle Andersson, Simon Arkeholt, Joakim Bertils, Jonas Ehn and Johannes Grundell.</description>
    </item>
    
  </channel>
</rss>